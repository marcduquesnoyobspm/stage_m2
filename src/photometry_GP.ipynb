{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bronze-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confused-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import celerite\n",
    "from celerite import terms\n",
    "import emcee\n",
    "import corner\n",
    "from scipy import signal\n",
    "from IPython.display import display, Math, Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operating-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marc/Stages/Stage_M2/src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = os.getcwd()\n",
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "looking-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marc/Stages/Stage_M2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_dir = os.path.dirname(dir)\n",
    "par_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amended-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params,time,flux):\n",
    "        gp.set_parameter_vector(params)\n",
    "        ll = gp.log_likelihood(flux)\n",
    "        return ll if np.isfinite(ll) else -np.inf\n",
    "\n",
    "### Définition de la likelihood ###\n",
    "def log_likelihood(params,time,flux):\n",
    "    gp.set_parameter_vector(params)\n",
    "    ll = gp.log_likelihood(flux)\n",
    "    return ll if np.isfinite(ll) else -np.inf\n",
    "\n",
    "### Définition du prior (uniforme) ###\n",
    "def log_prior(params):\n",
    "    if ((-30 < params[0] < 20) and (-10 < params[1] < 10) and (5 < params[2] < 7)) :\n",
    "        return 0\n",
    "    return -np.inf\n",
    "\n",
    "### Définition du posterior ###\n",
    "def log_probability(params,time,flux):\n",
    "    lp = log_prior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(params,time,flux) if np.isfinite(lp) else -np.inf\n",
    "\n",
    "    ### MCMC ###\n",
    "def run_mcmc(time,flux,gp) :\n",
    "    initial = gp.get_parameter_vector()\n",
    "    ndim, nwalkers = len(initial), 128\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability,args=(time,flux))\n",
    "\n",
    "    print(\"Running burn-in...\")\n",
    "    p0 = initial + 1e-8 * np.random.randn(nwalkers, ndim)\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 100,progress=True)\n",
    "\n",
    "    print(\"Running production...\")\n",
    "    sampler.reset()\n",
    "    sampler.run_mcmc(p0, 1000,progress=True)\n",
    "    print(\"Finished\")\n",
    "    \n",
    "    likelihood = gp.log_likelihood(flux)\n",
    "    af = sampler.acceptance_fraction\n",
    "    \n",
    "    print(\"Mean acceptance fraction:\", np.mean(af))\n",
    "    print(\"parameter_dict:\\n{0}\\n\".format(gp.get_parameter_dict()))\n",
    "    print(\"Final MCMC log likelihood: {0}\".format(gp.log_likelihood(flux)))\n",
    "    return(sampler,likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "postal-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_building(param,time,flux,error) :\n",
    "    bounds = dict(log_S0= (None,None), log_Q = (-10,10), log_omega0 = (5,7))\n",
    "    #kernel = terms.SHOTerm(log_S0=7., log_Q=2.5, log_omega0=5.)\n",
    "    kernel = terms.SHOTerm(log_S0=param[0], log_Q=param[1], log_omega0=param[2],bounds=bounds)\n",
    "\n",
    "\n",
    "    gp = celerite.GP(kernel,mean=np.mean(flux))\n",
    "    gp.compute(time,yerr=error)\n",
    " \n",
    "    print(\"Initial log likelihood: {0}\".format(gp.log_likelihood(flux)))\n",
    "    print(\"parameter_dict:\\n{0}\\n\".format(gp.get_parameter_dict()))\n",
    "    \n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improving-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA ###\n",
    "photometry_data = {\"TESS_18_19\" : \"/data/TESS_18_19_data.dat\"}#,\n",
    "#        \"TESS_20_0\" : \"/data/TESS_20_0_data.fits\",\n",
    "#        \"TESS_20_1\" : \"/data/TESS_20_1_data.fits\",\n",
    "#        \"TESS_21\" : \"/data/TESS_21_data.fits\"}\n",
    "\n",
    "sectors_names = {\"TESS_18_19\" : [\"All\"]}#,\"Sector1\",\"Sector2\",\"Sector3\"]}#,\n",
    "#                 \"TESS_20_0\" : [\"All\",\"Sector1\",\"Sector2\"],\n",
    "#                 \"TESS_20_1\" : [\"All\",\"Sector1\",\"Sector2\"],\n",
    "#                 \"TESS_21\" : [\"All\",\"Sector1\",\"Sector2\"]}\n",
    "\n",
    "photometry_sectors = {\"TESS_18_19\" : {\"All\" : np.array([1437,1517])}}#,\n",
    "#                                      \"Sector1\" : np.array([1437,1468]),\n",
    "#                                       \"Sector2\" : np.array([1468,1491]),\n",
    "#                                       \"Sector3\" : np.array([1491,1517])},\n",
    "#                       \"TESS_20_0\" : {\"All\" : np.array([2174,2200]),\n",
    "#                                      \"Sector1\" : np.array([2174,2186]),\n",
    "#                                      \"Sector2\" : np.array([2186,2200])},\n",
    "#                       \"TESS_20_1\" : {\"All\" : np.array([2200,2228]),\n",
    "#                                      \"Sector1\" : np.array([2200,2214]),\n",
    "#                                      \"Sector2\" : np.array([2214,2228])},\n",
    "#                       \"TESS_21\" : {\"All\" : np.array([2228,2254]),\n",
    "#                                      \"Sector1\" : np.array([2228,2242]),\n",
    "#                                      \"Sector2\" : np.array([2242,2254])}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powerful-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Params ###\n",
    "initial_params = [1,2.5,5.8]\n",
    "mask_dumps = np.array([])\n",
    "start_dumps = np.array([1441.024,1444.026,1447.026,1450.026,1451.552,1454.588,1457.588,1460.588,1463.588,1468.379,1471.505,1474.630,1481.276,1484.401,1487.526,1491.627,1494.797,1497.922,1501.046,1504.702,1507.859,1510.984,1514.109])\n",
    "end_dumps = np.array([1441.033,1444.033,1447.033,1450.033,1451.555,1454.595,1457.595,1460.595,1463.595,1468.387,1471.512,1474.637,1481.283,1484.408,1487.533,1491.634,1494.807,1497.931,1501.051,1504.705,1507.872,1510.995,1514.121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organizational-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Likelihood</th>\n",
       "      <th>Log S0</th>\n",
       "      <th>Log Q</th>\n",
       "      <th>Log w0</th>\n",
       "      <th>Inc - S0</th>\n",
       "      <th>Inc + S0</th>\n",
       "      <th>Inc - Q</th>\n",
       "      <th>Inc + Q</th>\n",
       "      <th>Inc - w0</th>\n",
       "      <th>Inc + w0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Photometry</th>\n",
       "      <th>Sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TESS_18_19</th>\n",
       "      <th>All</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Likelihood Log S0 Log Q Log w0 Inc - S0 Inc + S0 Inc - Q  \\\n",
       "Photometry Sector                                                            \n",
       "TESS_18_19 All           NaN    NaN   NaN    NaN      NaN      NaN     NaN   \n",
       "\n",
       "                  Inc + Q Inc - w0 Inc + w0  \n",
       "Photometry Sector                            \n",
       "TESS_18_19 All        NaN      NaN      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Creating dataframe ###\n",
    "columns = [\"Photometry\",\"Sector\",\"Likelihood\",\"Log S0\",\"Log Q\",\"Log w0\",\"Inc - S0\",\"Inc + S0\",\"Inc - Q\",\"Inc + Q\",\"Inc - w0\",\"Inc + w0\"]\n",
    "rows = photometry_data.keys()\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for key in photometry_data.keys() :\n",
    "    for name in sectors_names[key] :\n",
    "        df2 = pd.DataFrame([[key,name],[]],columns=['Photometry','Sector'])\n",
    "        df = df.append(df2.loc[0])\n",
    "df.set_index([\"Photometry\",\"Sector\"],inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "heard-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log likelihood: -145850.463689708\n",
      "parameter_dict:\n",
      "OrderedDict([('kernel:log_S0', 1.0), ('kernel:log_Q', 2.5), ('kernel:log_omega0', 5.8)])\n",
      "\n",
      "      fun: -315003.5232299846\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  0.50640661, -13.07344072,  17.18290161])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 140\n",
      "      nit: 17\n",
      "     njev: 35\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-21.05789122,   2.1494279 ,   5.76454753])\n",
      "Final log-likelihood: 315003.5232299846\n",
      "[7.15606113e-10 8.57994844e+00 3.18794766e+02]\n",
      "Parameters: OrderedDict([('kernel:log_S0', -21.057891221376707), ('kernel:log_Q', 2.149427904079407), ('kernel:log_omega0', 5.764547539956216)])\n",
      "Running burn-in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running production...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [17:22<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n",
      "Mean acceptance fraction: 0.6458671874999999\n",
      "parameter_dict:\n",
      "OrderedDict([('kernel:log_S0', -21.076197463939796), ('kernel:log_Q', 2.1746148710045565), ('kernel:log_omega0', 5.769057767513927)])\n",
      "\n",
      "Final MCMC log likelihood: 314999.7612855668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{log(S0)} = -21.058_{-0.015}^{0.015}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{log(Q)} = 2.152_{-0.031}^{0.032}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{log(w0)} = 5.765_{-0.002}^{0.002}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for photometry in photometry_data.keys() :\n",
    "    file = photometry_data[photometry]\n",
    "    \n",
    "    for sector in photometry_sectors[photometry].keys() :\n",
    "        \n",
    "        if photometry == \"TESS_18_19\" :\n",
    "            data = np.loadtxt(par_dir + file,usecols=(0,1))\n",
    "\n",
    "            time = data[:,0]\n",
    "            flux = data[:,1]\n",
    "            flux_error = 4.55e-5\n",
    "\n",
    "            for i in range(len(start_dumps)) :\n",
    "                dumps_indexes = np.argwhere((time>start_dumps[i])&(time<end_dumps[i]))\n",
    "                mask_dumps = np.append(mask_dumps,dumps_indexes)\n",
    "\n",
    "            time = np.delete(time,mask_dumps.astype(int))\n",
    "            flux = np.delete(flux,mask_dumps.astype(int))\n",
    "              \n",
    "        else :\n",
    "            hdul = fits.open(par_dir + file)\n",
    "            data = hdul[1].data\n",
    "            time = data['TIME']\n",
    "            flux = data['PDCSAP_FLUX']\n",
    "            flux_error = data['PDCSAP_FLUX_ERR']\n",
    "\n",
    "        index = np.argwhere((time > photometry_sectors[photometry][sector][0]) & (time < photometry_sectors[photometry][sector][1]))\n",
    "        time = np.ndarray.flatten(time[index])\n",
    "        flux = np.ndarray.flatten(flux[index])\n",
    "        \n",
    "        if photometry != \"TESS_18_19\" :\n",
    "            flux_error = np.ndarray.flatten(flux_error[index])\n",
    "        \n",
    "        gp = gp_building(initial_params,time,flux,flux_error)\n",
    "\n",
    "        ### Minimize ###\n",
    "        from scipy.optimize import minimize\n",
    "\n",
    "        def neg_log_like(params, y, gp):\n",
    "            gp.set_parameter_vector(params)\n",
    "            return -gp.log_likelihood(y)\n",
    "        # extract our initial guess at parameters\n",
    "        # from the celerite kernel and put it in a \n",
    "        # vector:\n",
    "        p0 = gp.get_parameter_vector()\n",
    "        bounds = gp.get_parameter_bounds()\n",
    "\n",
    "        # run optimization:\n",
    "        results = minimize(neg_log_like, p0, method='L-BFGS-B',bounds=bounds,args=(flux, gp))\n",
    "        print(results)\n",
    "        print(\"Final log-likelihood: {0}\".format(-results.fun))\n",
    "        print(np.exp(results.x))\n",
    "        print(\"Parameters: {0}\".format(gp.get_parameter_dict()))\n",
    "        gp.set_parameter_vector(results.x)\n",
    "\n",
    "        sampler,likelihood = run_mcmc(time,flux,gp)\n",
    "        df.loc[(photometry,sector),['Likelihood']] = likelihood\n",
    "        \n",
    "        ## Posteriors ###\n",
    "        flat_samples = sampler.get_chain(flat=True)\n",
    "        labels = [\"log(S0)\",\"log(Q)\",\"log(w0)\"]\n",
    "\n",
    "        posteriors = np.array([])\n",
    "        posteriors_errors = np.array([])\n",
    "#         fig = corner.corner(flat_samples, labels=labels, truths=[None,None,np.log(2*np.pi*24*60/30.4)])\n",
    "#         plt.title(\"Posteriors_MCMC_%s_%s\"%(photometry,sector))\n",
    "#         plt.savefig(par_dir + \"/plots/%s/%s/Posteriors_MCMC_%s_%s.pdf\"%(photometry,sector,photometry,sector),bbox_inches='tight')\n",
    "#         plt.close()  \n",
    "\n",
    "#         x = np.linspace(np.min(time),np.max(time),15000)\n",
    "#         pred_mean, pred_var = gp.predict(flux, x, return_var=True)\n",
    "#         pred_std = np.sqrt(pred_var)\n",
    "\n",
    "#         color = \"#ff7f0e\"\n",
    "#         plt.figure()\n",
    "#         plt.scatter(time,flux,s=1)\n",
    "#         plt.plot(x, pred_mean, color=color)\n",
    "#         plt.fill_between(x, pred_mean+pred_std, pred_mean-pred_std, color=color, alpha=0.3, edgecolor=\"none\",interpolate=True)\n",
    "#         plt.xlabel(\"x\")\n",
    "#         plt.ylabel(\"y\")\n",
    "#         plt.ylim(np.min(flux),np.max(flux))\n",
    "#         plt.title(\"Fit_MCMC_%s_%s\"%(photometry,sector))\n",
    "#         plt.savefig(par_dir + \"/plots/%s/%s/Fit_MCMC_%s_%s.pdf\"%(photometry,sector,photometry,sector),bbox_inches='tight')\n",
    "#         plt.close() \n",
    "\n",
    "        for i in range(flat_samples.shape[1]):\n",
    "\n",
    "            mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "            value = np.percentile(flat_samples[:, i], [50])\n",
    "            q = np.diff(mcmc)\n",
    "            txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "            txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "            display(Math(txt))\n",
    "            posteriors = np.append(posteriors,value)\n",
    "            posteriors_errors = np.append(posteriors_errors,q)\n",
    "            \n",
    "        df.loc[(key,sector),\"Log S0\":\"Log w0\"] = posteriors\n",
    "        df.loc[(key,sector),\"Inc - S0\" : \"Inc + w0\"] = posteriors_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dated-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(par_dir + '/data/Posteriors_photometries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
